{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/xenova/transformers.js/main/scripts/requirements.txt\n",
    "!wget https://raw.githubusercontent.com/xenova/transformers.js/main/scripts/convert.py\n",
    "!pip install -r requirements.txt -q\n",
    "!pip install huggingface_hub -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from huggingface_hub import HfApi, notebook_login, whoami, create_repo, ModelCard, ModelCardData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Log in to ðŸ¤— hub**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_login()\n",
    "user = whoami()['name']\n",
    "api = HfApi()\n",
    "print(f\"Logged in to ðŸ¤— as {user}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model to convert**  \n",
    "Pick a model from the  [ðŸ¤— Hub](https://huggingface.co/models).  \n",
    "Optional: \n",
    "If your user is different from `ORG`, you can set it in the `user` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"ORG/MODEL-ID\" # @param {type:\"string\"}\n",
    "user = \"\" # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convert the model to ONNX**\n",
    "This might take a moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"models\", exist_ok=True)\n",
    "!python convert.py --quantize --model_id {model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = model.split(\"/\")[-1]\n",
    "model_org = user or model.split(\"/\")[0] # if user is not provided, use the model org\n",
    "repo_id = f\"{model_org}/{model_name}\" # new repo id\n",
    "print(f\"Repo ID: {repo_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create new repo** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_url = create_repo(repo_id, exist_ok=True) # creates a new repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload the model to the hub\n",
    "api.upload_folder(\n",
    "    folder_path=f\"models/{model}\", # default output path from convert.py\n",
    "    repo_id=repo_id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "card = ModelCard.load(model) # get the old model card\n",
    "card_meta = card.data.to_dict()\n",
    "card_meta['library_name'] = \"transformers.js\"\n",
    "card_meta['tags'] += [\"onnx\"]\n",
    "card_meta = ModelCardData(**card_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add transformers.js modelcard template to existing model card\n",
    "content = f\"\"\"\n",
    "---\n",
    "{card_meta.to_yaml()}\n",
    "---\n",
    "\n",
    "https://huggingface.co/{model} with ONNX weights to be compatible with Transformers.js.  \n",
    "\n",
    "{card.text}  \n",
    "---\n",
    "  \n",
    "Note: Having a separate repo for ONNX weights is intended to be a temporary solution until WebML gains more traction. If you would like to make your models web-ready, we recommend converting to ONNX using [ðŸ¤— Optimum](https://huggingface.co/docs/optimum/index) and structuring your repo like this one (with ONNX weights located in a subfolder named `onnx`).\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelCard(content).push_to_hub(repo_id) # push the new model card to the hub"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
